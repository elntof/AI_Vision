# === [1. 기본 설정] ===
import os, re, time, random, json, math, csv
from pathlib import Path
from collections import Counter

import numpy as np
import torch
from torchvision import transforms as T
from PIL import Image, ImageOps

import pandas as pd
import matplotlib.pyplot as plt
from matplotlib import patches
from matplotlib.colors import ListedColormap
from IPython.display import clear_output, display
from tqdm.auto import tqdm

# 시드 & 디바이스
def seed_everything(seed=42):
    random.seed(seed); np.random.seed(seed)
    os.environ["PYTHONHASHSEED"] = str(seed)
    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
seed_everything(42)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"[INFO] device={device} | CUDA={torch.cuda.is_available()}")

# 전처리 / ROI (학습과 동일하게)
class CropROI:
    def __init__(self, xywh): self.x, self.y, self.w, self.h = map(int, xywh)
    def __call__(self, img: Image.Image):
        img = ImageOps.exif_transpose(img)
        W, H = img.size
        x = max(0, min(self.x, W-1)); y = max(0, min(self.y, H-1))
        w = max(1, min(self.w, W-x));  h = max(1, min(self.h, H-y))
        return img.crop((x, y, x+w, y+h))

IMAGENET_MEAN = [0.485, 0.456, 0.406]
IMAGENET_STD  = [0.229, 0.224, 0.225]
IMG_SIZE      = 224
ROI_RECT      = (40, 0, 200, 555)

valtest_tfms = T.Compose([
    CropROI(ROI_RECT),
    T.Grayscale(num_output_channels=3),
    T.Resize((IMG_SIZE, IMG_SIZE), interpolation=T.InterpolationMode.BILINEAR),
    T.ToTensor(),
    T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),
])

# 경로 설정
TEST_DIR   = Path(r"test_rawdata\Y0\251006")                  # 테스트 이미지 폴더
CSV_OUT    = Path("Predictions_Y0_251006.csv")                # 결과 CSV
MODEL_NAME = "vit_small_patch16_224"                          # timm 모델명
CHECKPOINT = Path(r"./vit_melted_icing_iced_best_ema.pth")    # 현재 폴더의 EMA 가중치

assert TEST_DIR.exists(), f"TEST_DIR not found: {TEST_DIR.resolve()}"

def natural_key(s: str):
    """파일 정렬 유틸"""
    base = os.path.basename(str(s))
    return [int(t) if t.isdigit() else t.lower() for t in re.split(r"(\d+)", base)]

# ROI 오버레이 프리뷰(랜덤 1장)
try:
    EXTS = {".jpg", ".jpeg", ".png", ".bmp", ".tif", ".tiff"}
    candidates = [p for p in TEST_DIR.rglob("*") if p.suffix.lower() in EXTS]
    if len(candidates) == 0:
        print(f"[ROI PREVIEW] No images found under: {TEST_DIR}")
    else:
        sample = random.choice(candidates)
        with Image.open(sample) as im:
            im = ImageOps.exif_transpose(im).convert("RGB")
            W, H = im.size
            x, y, w, h = map(int, ROI_RECT)
            # 원본 크기에 맞춰 경계 보정
            x = max(0, min(x, W - 1)); y = max(0, min(y, H - 1))
            w = max(1, min(w, W - x)); h = max(1, min(h, H - y))

            fig, ax = plt.subplots(figsize=(6, 6))
            ax.imshow(im)
            ax.add_patch(patches.Rectangle((x, y), w, h,
                                           linewidth=2.0, edgecolor="lime", facecolor="none"))
            ax.set_title(f"[x={x}, y={y}, w={w}, h={h}]")
            ax.set_axis_off(); ax.set_aspect('equal', adjustable='box')
            plt.show()
except Exception as e:
    print(f"[ROI PREVIEW] failed: {e}")

# === [/### 1] ===

# === [2. 모델 로더] ===
import timm
import torch.nn as nn
import torch.nn.functional as F

DEFAULT_CLASS_NAMES = ["Iced", "Icing", "Melted"]  # 클래스
DROP_PATH_RATE = 0.1

def build_model(n_classes: int):
    m = timm.create_model(MODEL_NAME, pretrained=False, num_classes=n_classes, drop_path_rate=DROP_PATH_RATE)
    return m

def _strip_prefix(sd: dict, prefixes=("module.", "model.", "net.", "backbone.")):
    new_sd = {}
    for k, v in sd.items():
        nk = k
        changed = True
        while changed:
            changed = False
            for pf in prefixes:
                if nk.startswith(pf):
                    nk = nk[len(pf):]
                    changed = True
        new_sd[nk] = v
    return new_sd

def _extract_state_dict(blob: dict):
    """다양한 저장 포맷에서(EMA 우선) state_dict 추출"""
    if not isinstance(blob, dict):
        return blob, "raw"

    # EMA 후보
    for k in ["state_dict_ema", "ema_state_dict", "model_ema", "model_ema_state_dict"]:
        if k in blob:
            sd = blob[k]
            if isinstance(sd, dict) and "state_dict" in sd:
                sd = sd["state_dict"]
            if isinstance(sd, dict):
                return _strip_prefix(sd), "ema"

    # 일반 가중치 후보
    for k in ["state_dict", "model", "weights", "params", "net"]:
        if k in blob:
            sd = blob[k]
            if isinstance(sd, dict) and "state_dict" in sd:
                sd = sd["state_dict"]
            if isinstance(sd, dict):
                return _strip_prefix(sd), "std"

    # 최상위가 곧 state_dict
    return _strip_prefix(blob), "raw"

def infer_num_classes_from_state(sd: dict):
    # timm ViT head 이름 후보
    for key in ["head.weight", "fc.weight", "classifier.weight"]:
        w = sd.get(key, None)
        if isinstance(w, torch.Tensor) and w.dim()==2:
            return int(w.shape[0])
    # 혹시 중첩 구조
    if "model" in sd and isinstance(sd["model"], dict):
        return infer_num_classes_from_state(sd["model"])
    return None

def load_model_from_pth(path_pth: Path):
    raw = torch.load(path_pth, map_location="cpu")
    sd, kind = _extract_state_dict(raw)
    n_classes = infer_num_classes_from_state(sd) or len(DEFAULT_CLASS_NAMES)

    model = build_model(n_classes)
    missing, unexpected = model.load_state_dict(sd, strict=False)
    print(f"[LOAD] file={path_pth.name} kind={kind} num_classes={n_classes} "
          f"| missing={len(missing)} unexpected={len(unexpected)}")

    class_names = DEFAULT_CLASS_NAMES if n_classes==3 else [f"class_{i}" for i in range(n_classes)]
    return model.to(device).eval(), class_names

# 실제 로드
assert CHECKPOINT.exists(), f"Checkpoint not found: {CHECKPOINT.resolve()}"
print(f"[INFO] using checkpoint: {CHECKPOINT.name}")
model, CLASS_NAMES = load_model_from_pth(CHECKPOINT)
print("CLASS_NAMES =", CLASS_NAMES)
# === [/### 2] ===

# === [3. ViT 배치 분류 + 패널/CSV 저장] ===
import os, re, random, math, csv, json, time
from pathlib import Path
from datetime import datetime
from collections import Counter

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import timm
from torchvision import transforms as T
from PIL import Image, ImageOps

import matplotlib.pyplot as plt
from matplotlib import patches
from tqdm.auto import tqdm

def seed_everything(seed=42):
    """재현성 확보용 시드 고정"""
    random.seed(seed); np.random.seed(seed)
    os.environ["PYTHONHASHSEED"] = str(seed)
    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

seed_everything(42)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"[INFO] device={device} | CUDA={torch.cuda.is_available()}")

class CropROI:
    """학습 ROI와 동일한 영역 Crop"""
    def __init__(self, xywh):
        self.x, self.y, self.w, self.h = map(int, xywh)

    def __call__(self, img: Image.Image):
        img = ImageOps.exif_transpose(img)
        W, H = img.size
        x = max(0, min(self.x, W - 1)); y = max(0, min(self.y, H - 1))
        w = max(1, min(self.w, W - x));  h = max(1, min(self.h, H - y))
        return img.crop((x, y, x + w, y + h))

IMAGENET_MEAN = [0.485, 0.456, 0.406]
IMAGENET_STD  = [0.229, 0.224, 0.225]
IMG_SIZE      = 224
ROI_RECT      = (40, 0, 200, 555)

valtest_tfms = T.Compose([
    CropROI(ROI_RECT),
    T.Grayscale(num_output_channels=3),
    T.Resize((IMG_SIZE, IMG_SIZE), interpolation=T.InterpolationMode.BILINEAR),
    T.ToTensor(),
    T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),
])

# Paths / Config
IN_DIR     = Path(r"test_rawdata\Y0\251006")       # 입력 폴더
OUT_ROOT   = Path(r"results\Y0")                   # 출력 루트(날짜별 자동 생성)
CHECKPOINT = Path(r"./vit_melted_icing_iced_best_ema.pth")

MODEL_NAME     = "vit_small_patch16_224"
DROP_PATH_RATE = 0.1
DEFAULT_CLASS_NAMES = ["Iced", "Icing", "Melted"]

EXTS = {".jpg", ".jpeg", ".png", ".bmp", ".tif", ".tiff"}

assert IN_DIR.exists(), f"IN_DIR not found: {IN_DIR.resolve()}"
assert CHECKPOINT.exists(), f"Checkpoint not found: {CHECKPOINT.resolve()}"
print(f"[INFO] using checkpoint: {CHECKPOINT.name}")

# Model Loader
def build_model(n_classes: int):
    """timm ViT 생성"""
    return timm.create_model(MODEL_NAME, pretrained=False, num_classes=n_classes, drop_path_rate=DROP_PATH_RATE)

def _strip_prefix(sd: dict, prefixes=("module.", "model.", "net.", "backbone.")):
    """state dict key prefix 제거"""
    new_sd = {}
    for k, v in sd.items():
        nk = k
        changed = True
        while changed:
            changed = False
            for pf in prefixes:
                if nk.startswith(pf):
                    nk = nk[len(pf):]
                    changed = True
        new_sd[nk] = v
    return new_sd

def _extract_state_dict(blob: dict):
    """다양한 저장 포맷에서 state_dict(EMA 우선) 추출"""
    if not isinstance(blob, dict):
        return blob, "raw"

    for k in ["state_dict_ema", "ema_state_dict", "model_ema", "model_ema_state_dict"]:
        if k in blob:
            sd = blob[k]
            if isinstance(sd, dict) and "state_dict" in sd:
                sd = sd["state_dict"]
            if isinstance(sd, dict):
                return _strip_prefix(sd), "ema"

    for k in ["state_dict", "model", "weights", "params", "net"]:
        if k in blob:
            sd = blob[k]
            if isinstance(sd, dict) and "state_dict" in sd:
                sd = sd["state_dict"]
            if isinstance(sd, dict):
                return _strip_prefix(sd), "std"

    return _strip_prefix(blob), "raw"

def infer_num_classes_from_state(sd: dict):
    """head weight shape로 클래스 수 추정"""
    for key in ["head.weight", "fc.weight", "classifier.weight"]:
        w = sd.get(key, None)
        if isinstance(w, torch.Tensor) and w.dim() == 2:
            return int(w.shape[0])
    if "model" in sd and isinstance(sd["model"], dict):
        return infer_num_classes_from_state(sd["model"])
    return None

def load_model_from_pth(path_pth: Path):
    """pth 파일에서 모델 로드"""
    raw = torch.load(path_pth, map_location="cpu")
    sd, kind = _extract_state_dict(raw)
    n_classes = infer_num_classes_from_state(sd) or len(DEFAULT_CLASS_NAMES)

    model = build_model(n_classes)
    missing, unexpected = model.load_state_dict(sd, strict=False)
    print(f"[LOAD] file={path_pth.name} kind={kind} num_classes={n_classes} "
          f"| missing={len(missing)} unexpected={len(unexpected)}")

    class_names = DEFAULT_CLASS_NAMES if n_classes == 3 else [f"class_{i}" for i in range(n_classes)]
    return model.to(device).eval(), class_names

model, CLASS_NAMES = load_model_from_pth(CHECKPOINT)
print("CLASS_NAMES =", CLASS_NAMES)


# Utils
def natural_key(path: Path):
    """파일명 내 숫자를 고려한 natural sort key"""
    base = os.path.basename(str(path))
    return [int(t) if t.isdigit() else t.lower() for t in re.split(r"(\d+)", base)]

def list_images_sorted(folder: Path):
    """폴더 내 이미지 경로 natural sort"""
    paths = [p for p in folder.rglob("*") if p.suffix.lower() in EXTS]
    paths.sort(key=natural_key)
    return paths

def parse_dt_from_filename(fname: str):
    """파일명 내 6자리 숫자 2개(YYMMDD, HHMMSS)를 찾아 datetime 반환"""
    sixes = re.findall(r'(\d{6})', fname)
    if len(sixes) < 2:
        return None
    d, t = sixes[0], sixes[1]
    try:
        yy, mm, dd = int(d[:2]), int(d[2:4]), int(d[4:6])
        hh, mi, ss = int(t[:2]), int(t[2:4]), int(t[4:6])
        year = 2000 + yy
        return datetime(year, mm, dd, hh, mi, ss)
    except ValueError:
        return None

def fmt_mmdd_hhmm(dt):
    return dt.strftime("%m/%d_%H:%M") if isinstance(dt, datetime) else ""

def lot_prefix_from_name(fname: str):
    """장비_날짜 프리픽스(예: Y0_251006)"""
    parts = Path(fname).stem.split("_")
    if len(parts) >= 2:
        return f"{parts[0]}_{parts[1]}", parts[1]
    return "", ""

def ensure_outdir(root: Path, date6: str):
    """날짜별 출력 폴더 생성"""
    out_dir = root / date6 if date6 else root
    out_dir.mkdir(parents=True, exist_ok=True)
    return out_dir

def compute_lead_minutes(starts):
    """레이블 간 LEAD TIME 계산"""
    t_m, t_i, t_c = starts.get("Melted"), starts.get("Icing"), starts.get("Iced")
    icing_lead_str = ""
    iced_lead_str  = ""
    if t_m and t_i:
        icing_lead_str = f"{max(0, int(round((t_i - t_m).total_seconds()/60.0)))}"
    if t_i and t_c:
        iced_lead_str  = f"{max(0, int(round((t_c - t_i).total_seconds()/60.0)))}"
    return icing_lead_str, iced_lead_str

def compute_current_lead_minutes(starts, cur_dt):
    """Iced 최초 시각 ~ 현재 프레임 시각 리드타임(분)"""
    iced_start = starts.get("Iced")
    if iced_start is None or cur_dt is None or cur_dt < iced_start:
        return ""
    return f"{max(0, int(round((cur_dt - iced_start).total_seconds()/60.0)))}"

# -------- 패널 크기/레이아웃 파라미터 --------
W_PX, H_PX = 442, 238
DPI = 100
outer_margin = 8
gap = 6
img_gap = 8
title_gap = 5
title_fontsize = 12
value_fontsize = 10
start_fontsize = 9
stroke_w = 1.2
ASPECT_W, ASPECT_H = 1.0, 2.1
# -----------------------------------------

# Panel Rendering
DISPLAY_ORDER = ["Melted", "Icing", "Iced"]  # 좌→우 표시 순서
active_fill   = {"Melted": "#ffadad", "Icing": "#81CBF8", "Iced": "#5a63e2"}
inactive_fill = "#ffffff"

def render_panel(img_path: Path, probs: np.ndarray, pred_name: str, earliest_dt_by_class: dict, current_dt: datetime, out_path: Path):
    """파일명 / 리드타임 / 3박스(확률+Start 시각) / 원본 이미지 + ROI overlay"""
    name2p = {CLASS_NAMES[i]: float(probs[i]) for i in range(len(CLASS_NAMES))}

    h_img_area = H_PX - 2 * outer_margin
    w_img_area = int(h_img_area * ASPECT_W / ASPECT_H)
    left_width = W_PX - 2 * outer_margin - img_gap - w_img_area
    left_width = max(left_width, 1)

    side_max_w = (left_width - 2 * gap) / 3
    side_max_h = H_PX - outer_margin - title_gap - 14
    side = int(max(1, min(side_max_w, side_max_h)))

    x0 = outer_margin
    x1 = x0 + side + gap
    x2 = x1 + side + gap
    y0 = outer_margin
    title_y = y0 + side + title_gap

    x_img_area = outer_margin + left_width + img_gap
    y_img_area = outer_margin
    w_img_area = int(w_img_area)
    h_img_area = int(h_img_area)

    earliest_str = {k: fmt_mmdd_hhmm(v) if v else "" for k, v in earliest_dt_by_class.items()}
    icing_lead_str, iced_lead_str = compute_lead_minutes(earliest_dt_by_class)
    current_lead_str = compute_current_lead_minutes(earliest_dt_by_class, current_dt)

    fig = plt.figure(figsize=(W_PX / DPI, H_PX / DPI), dpi=DPI)
    ax = fig.add_axes([0, 0, 1, 1])
    ax.set_xlim(0, W_PX); ax.set_ylim(0, H_PX); ax.axis('off')

    # 좌측 상단: 정보
    info_x = outer_margin
    info_y_top = H_PX - outer_margin
    line_h = 22
    ax.text(info_x, info_y_top, f"{img_path.name}", ha="left", va="top", fontsize=10, color="#222222", fontweight="bold")
    ax.text(info_x, info_y_top - 1.2 * line_h, f"- Melted~Icing Time: {icing_lead_str} min" if icing_lead_str else "- Melted~Icing Time: ", ha="left", va="top", fontsize=10, color="#222222")
    ax.text(info_x, info_y_top - 2.2 * line_h, f"- Icing~Iced Time: {iced_lead_str} min" if iced_lead_str else "- Icing~Iced Time: ", ha="left", va="top", fontsize=10, color="#222222")
    ax.text(info_x, info_y_top - 3.2 * line_h, f"- Iced~Current Time: {current_lead_str} min" if current_lead_str else "- Iced~Current Time: ", ha="left", va="top", fontsize=10, color="#222222")

    # 좌측 하단: 3박스
    xs = [x0, x1, x2]
    for name, x_left in zip(DISPLAY_ORDER, xs):
        ax.text(x_left + side/2, title_y, name, ha="center", va="bottom", fontsize=title_fontsize, fontweight="bold", color="#000000")

        fc = active_fill.get(name, inactive_fill) if name == pred_name else inactive_fill
        rect = patches.Rectangle((x_left, y0), side, side, linewidth=stroke_w, edgecolor="black", facecolor=fc)
        ax.add_patch(rect)

        p_val = name2p.get(name, 0.0)
        ax.text(x_left + side/2, y0 + side*0.56, f"{p_val*100:.1f}%", ha="center", va="center", fontsize=value_fontsize, color="#000000", fontweight="bold")

        ax.text(x_left + side/2, y0 + side*0.30, earliest_str.get(name, ""), ha="center", va="center", fontsize=start_fontsize, color="#000000")

    # 우측: 원본 이미지 + ROI 오버레이
    with Image.open(img_path) as im:
        im = ImageOps.exif_transpose(im).convert("RGB")
        iw, ih = im.size
        scale = min(w_img_area / iw, h_img_area / ih) if iw > 0 and ih > 0 else 1.0
        w_fit, h_fit = iw * scale, ih * scale
        x_img0 = x_img_area + (w_img_area - w_fit) / 2
        y_img0 = y_img_area + (h_img_area - h_fit) / 2

        ax_img = fig.add_axes([x_img0 / W_PX, y_img0 / H_PX, w_fit / W_PX, h_fit / H_PX])
        ax_img.imshow(im, origin='upper')
        ax_img.set_xlim(0, iw); ax_img.set_ylim(ih, 0)
        ax_img.axis('off')

        rx, ry, rw, rh = map(int, ROI_RECT)
        ax_img.add_patch(patches.Rectangle((rx, ry), rw, rh, linewidth=1.2, edgecolor="lime", facecolor="none"))

    out_path.parent.mkdir(parents=True, exist_ok=True)
    fig.savefig(out_path, dpi=DPI, bbox_inches=None, pad_inches=0)
    plt.close(fig)

# Main Batch Loop
all_paths = list_images_sorted(IN_DIR)
print(f"[INFO] found {len(all_paths)} images under {IN_DIR}")

earliest_by_lot = {}   # lot별 최초 시각 누적
rows_csv = []          # CSV 누적 버퍼

pbar = tqdm(all_paths, desc="Simulating stream → panels", unit="img")
for img_path in pbar:
    fname = img_path.name
    lot_prefix, date6 = lot_prefix_from_name(fname)
    out_dir = ensure_outdir(OUT_ROOT, date6)
    out_path = out_dir / f"{img_path.stem}_panel.png"

    # inference
    with Image.open(img_path) as im:
        im = ImageOps.exif_transpose(im).convert("RGB")
        x = valtest_tfms(im).unsqueeze(0).to(device)

    with torch.no_grad():
        with torch.amp.autocast('cuda', enabled=torch.cuda.is_available()):
            logits = model(x)
            probs = torch.softmax(logits, dim=1).flatten().float().cpu().numpy()

    pred_name = CLASS_NAMES[int(np.argmax(probs))]

    # current datetime from filename
    cur_dt = parse_dt_from_filename(fname)

    # update earliest times by lot
    if lot_prefix not in earliest_by_lot:
        earliest_by_lot[lot_prefix] = {"Melted": None, "Icing": None, "Iced": None}
    starts = earliest_by_lot[lot_prefix]

    if cur_dt is not None:
        if starts.get(pred_name) is None or cur_dt < starts[pred_name]:
            starts[pred_name] = cur_dt

    # render/save panel
    render_panel(img_path, probs, pred_name, starts, cur_dt, out_path)

    # accumulate CSV row
    ts_str = (cur_dt.strftime("%Y-%m-%d %H:%M:%S")
              if cur_dt is not None
              else datetime.fromtimestamp(img_path.stat().st_mtime).strftime("%Y-%m-%d %H:%M:%S"))
    row = {
        "filename": img_path.name,
        "timestamp": ts_str,
        "pred_label": pred_name,
        "confidence": float(np.max(probs)),
    }
    for ci, cname in enumerate(CLASS_NAMES):
        row[f"p_{cname}"] = float(probs[ci])
    rows_csv.append(row)

# Save CSV
date6_for_csv = IN_DIR.name
csv_dir = ensure_outdir(OUT_ROOT, date6_for_csv)
csv_path = csv_dir / f"Predictions_{date6_for_csv}.csv"

df_csv = pd.DataFrame(rows_csv)
CSV_COL_ORDER = ["filename", "timestamp", "pred_label", "confidence"] + [f"p_{c}" for c in CLASS_NAMES]
df_csv = df_csv.reindex(columns=CSV_COL_ORDER)

df_csv.to_csv(csv_path, index=False, encoding="utf-8-sig")
print(f"[SAVE] CSV → {csv_path.resolve()}  ({len(df_csv)} rows)")

# 필요 시 이후 분석용 DataFrame
df = df_csv.copy()

print(f"[SAVE] Panels → {OUT_ROOT.resolve()} (by date folder)")
# === [/### 3] ===

